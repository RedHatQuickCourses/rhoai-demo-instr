= Model Serving with Red Hat AI Inference Server

== Introduction

Welcome to Model Serving with Red Hat AI Inference Server (RHAIIS). 

This training session was designed to provide you knowledge and skills to make decisions related to large language model (LLM) inference using the supported version of RHAIIS. 

This course begins with a review of Red Hat AI Inference Server 3.2.0, a key component of the Red Hat AI platform, by walking you through the essential first concepts, then we'll move into a lab deploying an LLM, monitor GPU and performing basic GPU memory tuning using vLLM configuration settings. 

**Red Hat AI Inference Server (RHAIIS)**. 

Available as a standalone product and included in Red Hat OpenShift AI and Red Hat Enterprise Linux AI, this supported platform provides a powerful and flexible solution for deploying high-performance large language models across any hybrid cloud environment.

RHAIIS provides a hardened, supported distribution of the **vLLM** software via pre-packaged containers, depending on GPU type. The vLLM open-source project is renowned for its high-throughput and memory-efficient performance, achieved through innovative techniques like PagedAttention and continuous batching.

image::rhaiis_containers.png[.RHAIIS Catalog]

== Overview and Objectives

Upon completing this lab, you will be able to:

 * Deploy RHAIIS with a validated model using a single Podman command.
 * Verify the model is serving correctly by interacting with its API.
 * Monitor the GPU's video memory (VRAM) usage in real-time.
 * Tune server parameters to control memory consumption and context length.
 * Deploy and test an alternative model to see the platform's flexibility.

== Prerequisites

Your lab environment has been pre-configured with the following:

* A Red Hat Enterprise Linux 9.x system with a valid subscription.
* An attached and configured NVIDIA data center GPU with drivers installed.
* Podman and the NVIDIA Container Toolkit are pre-installed.
* Credentials for **Red Hat account** to access `registry.redhat.io`. (Provided for this experience)
* A **Hugging Face account** with a User Access Token with read permissions. (Provided for this experience)











