<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>GPU Timeslicing :: OpenShift AI Lab environment instructions</title>
    <link rel="prev" href="gpu-sharing.html">
    <link rel="next" href="gpu-mig.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">OpenShift AI Lab environment instructions</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="rhoai-demo-instr" data-version="2.12">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">OpenShift AI Lab environment instructions</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Why Customers Need a MaaS Platform</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="intro.html">Serving at Scale</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="gpu-aas.html">Architecting GPU as a Service</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="gpu-sharing.html">GPU Sharing Technologies</a>
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="4">
    <a class="nav-link" href="gpu-time.html">GPU Timeslicing</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="gpu-mig.html">Multi-Instance GPU (MIG)</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="gpu-mps.html">NVIDIAâ€™s Multi-Process Service (MPS)</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="gpu-agg.html">GPU Aggregation</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="tensor.html">Tensor Parallelism</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="pipeline.html">Pipeline Parallelism</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="data-para.html">Data Parallelism</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="expert-para.html">Expert Parallelism</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="start.html">Models with GitOps</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="gpu-sizing.html">Sizing for GPUs</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="gpu-scaling.html">Scaling Architectures</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="vllm-adv.html">Advanced vLLM Configuration</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="gpu-multi.html">Lab: Multi-GPU Model Deployment</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="gpu-nodes.html">Lab: Multi-Node, Multi-GPU Deployment</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="gitops.html">Deploying Models with GitOps</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="api-reqs.html">API Gateway Requirements for MaaS</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="index.html">MaaS Logical Architecture</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="intro2.html">The Gateway&#8217;s Core Requirements</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="api_checklist.html">Hands-On Lab: Productizing and Consuming an AI Model</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="api-security.html">Securing the AI Factory: A Defense-in-Depth Approach</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter6/index.html">Agentic AI Placeholder</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter6/section1.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter6/section2.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter6/section3.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter6/section4.html">blank</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter5/index.html">LLM optimization and inference efficiency</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter5/section1.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter5/section2.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter5/section3.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter5/section4.html">blank</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../appendix/appendix.html">Appendix</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../LABENV/index.html">Lab Environment</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/rhoai_self_managed.html">OpenShift AI Lab</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/oai_install.html">OpenShift AI Install</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/minio-install.html">MinIO S3 Compatible Storage Setup</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/hyperscaler_lab_env.html">Cloud Provider Lab Environments</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/red-hat-docs.html">Red Hat Documentation Reference</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter2/index.html">Red Hat AI Inference Server</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/section1.html">Lab 1: Model Serving with Red Hat AI Inference Server</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/section2.html">Sizing for GPUs</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/section3.html">GPU Sharing Technologies</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/vllm-adv.html">Advanced vLLM Configuration</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">OpenShift AI Lab environment instructions</span>
    <span class="version">2.12</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">OpenShift AI Lab environment instructions</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">2.12</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">OpenShift AI Lab environment instructions</a></li>
    <li><a href="intro.html">Serving at Scale</a></li>
    <li><a href="gpu-aas.html">Architecting GPU as a Service</a></li>
    <li><a href="gpu-sharing.html">GPU Sharing Technologies</a></li>
    <li><a href="gpu-time.html">GPU Timeslicing</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">GPU Timeslicing</h1>
<div class="sect1">
<h2 id="_what_is_gpu_timeslicing_and_why_use_it"><a class="anchor" href="#_what_is_gpu_timeslicing_and_why_use_it"></a>What is GPU Timeslicing and Why Use It?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>GPU timeslicing is a software-based sharing technique that allows multiple workloads to run on a single GPU by dividing access to its compute resources over time. Unlike hardware partitioning (MIG), timeslicing gives each workload sequential access to the <strong>full power</strong> of the GPU for very short intervals.</p>
</div>
<div class="paragraph">
<p>This approach is a powerful tool for maximizing the ROI of your GPU infrastructure.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="title">Primary Use Cases</div>
<div class="ulist">
<ul>
<li>
<p><strong>Development and Testing:</strong> Give multiple developers simultaneous access to GPUs without the cost of dedicating a full device to each.</p>
</li>
<li>
<p><strong>Low-Traffic AI Inference:</strong> Serve multiple, distinct models from a single GPU, which is highly cost-effective when requests are sporadic.</p>
</li>
<li>
<p><strong>Improving Utilization:</strong> Ensure expensive GPUs are not sitting idle, driving up utilization rates and making AI workloads more economical.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_how_it_works_the_core_mechanism"><a class="anchor" href="#_how_it_works_the_core_mechanism"></a>How It Works: The Core Mechanism</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Timeslicing operates through a rapid, managed process of context switching, enabled by modern NVIDIA GPU architectures (Pascal and newer).</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Time Division:</strong> The GPU driver&#8217;s scheduler allocates brief time slices to each active workload, typically in a round-robin fashion.</p>
</li>
<li>
<p><strong>Compute Preemption:</strong> The GPU hardware can interrupt a running process (a kernel) when its time slice expires.</p>
</li>
<li>
<p><strong>Context Switching:</strong> The state of the outgoing process is saved, and the state of the incoming process is loaded. This context switch is optimized in hardware to minimize overhead.</p>
</li>
<li>
<p><strong>Shared Memory Pool:</strong> Crucially, all workloads sharing the GPU via timeslicing use the <strong>same VRAM memory pool</strong>. There is no separation or protection.</p>
</li>
</ol>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_the_critical_trade_off_performance_vs_isolation"><a class="anchor" href="#_the_critical_trade_off_performance_vs_isolation"></a>The Critical Trade-Off: Performance vs. Isolation</h2>
<div class="sectionbody">
<div class="paragraph">
<p>While timeslicing is excellent for maximizing utilization, it comes with a significant trade-off that every platform engineer must understand.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="title">No Isolation is the Biggest Risk</div>
<div class="paragraph">
<p>Timeslicing provides <strong>zero memory or fault isolation</strong> between workloads.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Memory Contention:</strong> If the combined memory usage of all containers exceeds the GPU&#8217;s capacity, one or more workloads will fail with a <code>CUDA out of memory</code> error.</p>
</li>
<li>
<p><strong>Fault Propagation:</strong> An error or crash in a single container can destabilize the GPU driver, potentially affecting <strong>every other workload</strong> running on that GPU.</p>
</li>
<li>
<p><strong>"Noisy Neighbor" Problem:</strong> A single, compute-intensive workload can consume a disproportionate amount of resources, leading to unpredictable performance and higher latency for other containers.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Because of these risks, timeslicing should be used with caution in production and is best suited for environments where workloads are trusted and performance requirements are not strictly guaranteed.</p>
</div>
</td>
</tr>
</table>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_practical_configuration"><a class="anchor" href="#_practical_configuration"></a>Practical Configuration</h2>
<div class="sectionbody">
<div class="paragraph">
<p>You can manage timeslicing settings directly on the node and configure your workloads to behave correctly in a shared environment.</p>
</div>
<div class="sect2">
<h3 id="_setting_the_timeslice_duration"><a class="anchor" href="#_setting_the_timeslice_duration"></a>Setting the Timeslice Duration</h3>
<div class="paragraph">
<p>The duration of each time slice can be configured on the host using <code>nvidia-smi</code>. Shorter slices allow for more responsive switching but incur higher overhead.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Set a SHORT (2ms) time slice, best for latency-sensitive tasks
nvidia-smi compute-policy --set-timeslice=1

# Set a MEDIUM (10ms) time slice, a balanced default
nvidia-smi compute-policy --set-timeslice=2

# Set a LONG (30ms) time slice, best for throughput-oriented tasks
nvidia-smi compute-policy --set-timeslice=3</code></pre>
</div>
</div>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="gpu-sharing.html">GPU Sharing Technologies</a></span>
  <span class="next"><a href="gpu-mig.html">Multi-Instance GPU (MIG)</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
