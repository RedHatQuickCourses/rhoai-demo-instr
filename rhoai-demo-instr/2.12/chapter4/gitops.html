<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Deploying Models with GitOps :: OpenShift AI Lab environment instructions</title>
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">OpenShift AI Lab environment instructions</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="rhoai-demo-instr" data-version="2.12">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">OpenShift AI Lab environment instructions</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Why Customers Need a MaaS Platform</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter1/intro.html">Serving at Scale</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter1/gpu-aas.html">Architecting GPU as a Service</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter1/gpu-sharing.html">GPU Sharing Technologies</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../chapter1/gpu-time.html">GPU Timeslicing</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../chapter1/gpu-mig.html">Multi-Instance GPU (MIG)</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../chapter1/gpu-mps.html">NVIDIAâ€™s Multi-Process Service (MPS)</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter1/gpu-agg.html">GPU Aggregation</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../chapter1/tensor.html">Tensor Parallelism</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../chapter1/pipeline.html">Pipeline Parallelism</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../chapter1/data-para.html">Data Parallelism</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../chapter1/expert-para.html">Expert Parallelism</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter1/start.html">Models with GitOps</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../chapter1/gpu-sizing.html">Sizing for GPUs</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../chapter1/gpu-scaling.html">Scaling Architectures</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../chapter1/vllm-adv.html">Advanced vLLM Configuration</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../chapter1/gpu-multi.html">Lab: Multi-GPU Model Deployment</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../chapter1/gpu-nodes.html">Lab: Multi-Node, Multi-GPU Deployment</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../chapter1/gitops.html">Deploying Models with GitOps</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter1/api-reqs.html">API Gateway Requirements for MaaS</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../chapter1/index.html">MaaS Logical Architecture</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../chapter1/intro2.html">The Gateway&#8217;s Core Requirements</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../chapter1/api_checklist.html">Hands-On Lab: Productizing and Consuming an AI Model</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../chapter1/api-security.html">Securing the AI Factory: A Defense-in-Depth Approach</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter6/index.html">Agentic AI Placeholder</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter6/section1.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter6/section2.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter6/section3.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter6/section4.html">blank</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter5/index.html">LLM optimization and inference efficiency</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter5/section1.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter5/section2.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter5/section3.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter5/section4.html">blank</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../appendix/appendix.html">Appendix</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../LABENV/index.html">Lab Environment</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/rhoai_self_managed.html">OpenShift AI Lab</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/oai_install.html">OpenShift AI Install</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/minio-install.html">MinIO S3 Compatible Storage Setup</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/hyperscaler_lab_env.html">Cloud Provider Lab Environments</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/red-hat-docs.html">Red Hat Documentation Reference</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter2/index.html">Red Hat AI Inference Server</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/section1.html">Lab 1: Model Serving with Red Hat AI Inference Server</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/section2.html">Sizing for GPUs</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/section3.html">GPU Sharing Technologies</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/vllm-adv.html">Advanced vLLM Configuration</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">OpenShift AI Lab environment instructions</span>
    <span class="version">2.12</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">OpenShift AI Lab environment instructions</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">2.12</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">OpenShift AI Lab environment instructions</a></li>
    <li><a href="gitops.html">Deploying Models with GitOps</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Deploying Models with GitOps</h1>
<div class="sect1">
<h2 id="_introduction"><a class="anchor" href="#_introduction"></a>Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Up to this point, we have primarily used the OpenShift AI Dashboard to deploy our models. While the UI is an excellent way to get started and experiment, production environments demand a more robust, repeatable, and automated approach. This is where a GitOps workflow becomes essential.</p>
</div>
<div class="paragraph">
<p>In this module, we will shift our focus from manual UI-driven deployments to a declarative, code-based methodology. By managing our model deployments as code, we can leverage standard GitOps practices for version control, peer review, and automated rollouts. This is the standard practice for managing production-grade infrastructure and applications.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_lab_story"><a class="anchor" href="#_lab_story"></a>Lab Story</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The Platform Engineering team at "InnovateForward Corp" has successfully proven they can deploy models using various scaling patterns. Now, they must standardize this process to prepare for the influx of new models required by the application and agentic AI teams. Manually deploying each model through the UI is not scalable and is prone to human error.</p>
</div>
<div class="paragraph">
<p>Their new mission is to establish a standardized GitOps workflow for model deployment. They will use a Helm chart to declaratively define and deploy a new model. This will create a repeatable pattern that can be integrated into their CI/CD pipelines, ensuring that every model deployed to their AI Factory adheres to the same configuration standards and passes through the same automated process.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_kserve_objects_the_building_blocks"><a class="anchor" href="#_kserve_objects_the_building_blocks"></a>KServe Objects: The Building Blocks</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To manage deployments declaratively, we need to understand the two primary Kubernetes objects that KServe uses:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>InferenceService</strong></dt>
<dd>
<p>This object defines the model itself. It specifies details like the model&#8217;s location (its <code>storageUri</code>), any custom arguments it requires, and the resources it needs (CPU, memory, GPUs).</p>
</dd>
<dt class="hdlist1"><strong>ServingRuntime</strong></dt>
<dd>
<p>This object defines the runtime environment for the model. It specifies the container image to use (e.g., the vLLM image), the commands to run, and the environment variables required to start the server. A single <code>ServingRuntime</code> can be reused by multiple <code>InferenceServices</code>.</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_the_vllm_kserve_helm_chart"><a class="anchor" href="#_the_vllm_kserve_helm_chart"></a>The vLLM KServe Helm Chart</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To simplify the process of creating these KServe objects, Red Hat Services provides a Helm chart specifically for deploying vLLM instances. Helm charts package up all the necessary Kubernetes manifests into a single, configurable unit, making deployments much easier to manage.</p>
</div>
<div class="paragraph">
<p>You can find the chart here: <a href="https://github.com/redhat-ai-services/helm-charts/tree/main/charts/vllm-kserve" class="bare">https://github.com/redhat-ai-services/helm-charts/tree/main/charts/vllm-kserve</a></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The vLLM KServe Helm chart does not currently support multi-node deployments. Multi-node deployments must be managed with custom manifests as shown in the previous lab.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_lab_deploying_a_model_with_helm"><a class="anchor" href="#_lab_deploying_a_model_with_helm"></a>Lab: Deploying a Model with Helm</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In this lab, we will deploy the <code>granite-guardian-3.2-5b</code> model, which will be used in the later LlamaStack agent labs. This time, we will use the Helm chart to manage the deployment.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
If you don&#8217;t already have the Helm CLI installed, please refer to the official documentation: <a href="https://helm.sh/docs/intro/install/" class="bare">https://helm.sh/docs/intro/install/</a>
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="_step_1_add_the_helm_repository"><a class="anchor" href="#_step_1_add_the_helm_repository"></a>Step 1: Add the Helm Repository</h3>
<div class="paragraph">
<p>First, we need to add the Red Hat AI Services Helm repository to our local Helm client so it knows where to find the chart.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Add the repository:</p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">helm repo add redhat-ai-services https://redhat-ai-services.github.io/helm-charts/</code></pre>
</div>
</div>
</li>
<li>
<p>Update your local chart information:</p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">helm repo update redhat-ai-services</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_step_2_deploy_the_model_using_helm"><a class="anchor" href="#_step_2_deploy_the_model_using_helm"></a>Step 2: Deploy the Model using Helm</h3>
<div class="paragraph">
<p>Now, we can use a single <code>helm upgrade</code> command to deploy our model. The <code>-i</code> flag tells Helm to install the chart if it&#8217;s not already present.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">helm upgrade -i granite-guardian redhat-ai-services/vllm-kserve --version 0.4.2 \
  --set fullnameOverride="granite-guardian" \
  --set image.tag="rhoai-2.19-cuda" \
  --set model.uri="oci://quay.io/redhat-ai-services/modelcar-catalog:granite-guardian-3.2-5b" \
  --set model.args={"--max-model-len=20000"} \
  --set deploymentMode=RawDeployment \
  --set scaling.rawDeployment.deploymentStrategy.type=Recreate \
  -n serving-at-scale</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_understanding_the_helm_parameters"><a class="anchor" href="#_understanding_the_helm_parameters"></a>Understanding the Helm Parameters</h3>
<div class="paragraph">
<p>Let&#8217;s break down the key parameters we used in that command:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>fullnameOverride</code></dt>
<dd>
<p>Overrides the default name of the Kubernetes resources created by Helm. We set it to <code>granite-guardian</code> for clarity.</p>
</dd>
<dt class="hdlist1"><code>image.tag</code></dt>
<dd>
<p>Specifies the tag for the vLLM container image, ensuring we use a version consistent with our OpenShift AI environment.</p>
</dd>
<dt class="hdlist1"><code>model.uri</code></dt>
<dd>
<p>Defines the location of the model to be served, using the OCI path to our ModelCar container.</p>
</dd>
<dt class="hdlist1"><code>model.args</code></dt>
<dd>
<p>Passes arguments directly to the vLLM server. Here, we limit the context length to <code>20000</code> to ensure the model fits on our available GPU.</p>
</dd>
<dt class="hdlist1"><code>deploymentMode</code></dt>
<dd>
<p>We set this to <code>RawDeployment</code> to deploy the model without the dependencies of Knative and Service Mesh, which simplifies the deployment in our resource-constrained lab environment.</p>
</dd>
<dt class="hdlist1"><code>scaling.rawDeployment.deploymentStrategy.type</code></dt>
<dd>
<p>Sets the update strategy to <code>Recreate</code>. This tells Kubernetes to terminate the old pod before creating a new one during an upgrade. This is useful in our lab to conserve GPU resources but would cause downtime in a production environment.</p>
</dd>
<dt class="hdlist1"><code>-n serving-at-scale</code></dt>
<dd>
<p>Specifies the namespace where the model should be deployed.</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_step_3_verify_the_deployment"><a class="anchor" href="#_step_3_verify_the_deployment"></a>Step 3: Verify the Deployment</h3>
<div class="paragraph">
<p>Check that the pod was created and has started successfully.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">oc get pods -n serving-at-scale</code></pre>
</div>
</div>
<div class="paragraph">
<p>You should see a pod named <code>granite-guardian-predictor-&#8230;&#8203;</code> in the <code>Running</code> state. You have now successfully deployed a model using a repeatable, GitOps-friendly workflow.</p>
</div>
</div>
</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
